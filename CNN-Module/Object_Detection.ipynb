{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as js\n",
    "import tensorflow as tf\n",
    "from os import listdir as ld\n",
    "from os import path\n",
    "from keras.models import Model #type: ignore\n",
    "from keras import layers,models,regularizers #type: ignore\n",
    "from keras.utils import to_categorical #type: ignore\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config_CNN.json\",'r') as file:\n",
    "    paths = js.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "GRID_SIZE = 8\n",
    "NUM_CLASSES = 80  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        annotations = js.load(f)\n",
    "\n",
    "    label_map = defaultdict(list)  # {img_id: [bbox_dicts]}\n",
    "    for ann in annotations:\n",
    "        label_map[ann[\"img_id\"]].append({\n",
    "            \"bbox\": ann[\"bbox\"],\n",
    "            \"category_id\": ann[\"category_id\"]\n",
    "        })\n",
    "    return label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths['Instance_Train'], 'r') as f:\n",
    "    instance_train = js.load(f)\n",
    "    \n",
    "unique_cats = sorted({ann[\"id\"] for ann in instance_train['categories']})\n",
    "category_id_to_index = {cat_id: i for i, cat_id in enumerate(unique_cats)}\n",
    "num_classes = len(category_id_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_and_labels(img_path, ann_list, num_classes=NUM_CLASSES, grid_size=GRID_SIZE):\n",
    "    image = Image.open(img_path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n",
    "    image = np.array(image) / 255.0\n",
    "    label_tensor = np.zeros((grid_size, grid_size, 5 + num_classes), dtype=np.float32)\n",
    "\n",
    "    for ann in ann_list:\n",
    "        x, y, w, h = ann[\"bbox\"]\n",
    "        x_center = (x + w / 2) / IMG_SIZE\n",
    "        y_center = (y + h / 2) / IMG_SIZE\n",
    "        w /= IMG_SIZE\n",
    "        h /= IMG_SIZE\n",
    "        grid_x = int(x_center * grid_size)\n",
    "        grid_y = int(y_center * grid_size)\n",
    "\n",
    "        if grid_x >= grid_size: grid_x = grid_size - 1\n",
    "        if grid_y >= grid_size: grid_y = grid_size - 1\n",
    "\n",
    "        label_tensor[grid_y, grid_x, 0:4] = [x_center, y_center, w, h]\n",
    "        label_tensor[grid_y, grid_x, 4] = 1.0  # Object confidence\n",
    "        class_index = category_id_to_index[ann[\"category_id\"]]\n",
    "        label_tensor[grid_y, grid_x, 5 + class_index] = 1.0\n",
    "\n",
    "    return image.astype(np.float32), label_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_dataset(image_dir, annotation_map, batch_size=32):\n",
    "    image_files = list(annotation_map.keys())\n",
    "\n",
    "    def generator():\n",
    "        for img_file in image_files:\n",
    "            img_path = path.join(image_dir, img_file)\n",
    "            if not path.exists(img_path):\n",
    "                continue\n",
    "            img, label = preprocess_image_and_labels(img_path, annotation_map[img_file])\n",
    "            yield img, label\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(GRID_SIZE, GRID_SIZE, 5 + NUM_CLASSES), dtype=tf.float32)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dataset = dataset.shuffle(512).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    dataset = dataset.repeat()  \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block(x, filters):\n",
    "    path1 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    path2 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    path2 = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(path2)\n",
    "    path3 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    path3 = layers.Conv2D(filters, (5, 5), padding='same', activation='relu')(path3)\n",
    "    path4 = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    path4 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(path4)\n",
    "    return layers.Concatenate()([path1, path2, path3, path4])\n",
    "\n",
    "def mbconv_block(x, filters, kernel_size=(3, 3), strides=(1, 1), expand_ratio=6):\n",
    "    input_tensor = x\n",
    "    in_channels = x.shape[-1]\n",
    "    expanded = layers.Conv2D(in_channels * expand_ratio, (1, 1), padding='same', use_bias=False,kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    expanded = layers.BatchNormalization()(expanded)\n",
    "    expanded = layers.ReLU()(expanded)\n",
    "    depthwise = layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=False)(expanded)\n",
    "    depthwise = layers.BatchNormalization()(depthwise)\n",
    "    depthwise = layers.ReLU()(depthwise)\n",
    "    projected = layers.Conv2D(filters, (1, 1), padding='same', use_bias=False,kernel_regularizer=regularizers.l2(0.01))(depthwise)\n",
    "    projected = layers.BatchNormalization()(projected)\n",
    "    if strides == (1, 1) and in_channels == filters:\n",
    "        x = layers.Add()([input_tensor, projected])\n",
    "    else:\n",
    "        x = projected\n",
    "    return x\n",
    "\n",
    "def efficient_yolo_model(input_shape=(128, 128, 3), grid_size=8, num_classes=80):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', activation='relu',kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
    "    x = mbconv_block(x, 64, strides=(1, 1), expand_ratio=2)\n",
    "    x = mbconv_block(x, 128, strides=(2, 2), expand_ratio=2)\n",
    "    x = mbconv_block(x, 256, strides=(2, 2), expand_ratio=4)\n",
    "    x = inception_block(x, 128)\n",
    "    x = inception_block(x, 128)\n",
    "    x = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same',kernel_regularizer=regularizers.l2(0.01))(x)  \n",
    "    x = layers.Conv2D(85, (1, 1), padding='same')(x)  \n",
    "    model = models.Model(inputs, x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou_yolo(true_boxes, pred_boxes):\n",
    "    true_xy = true_boxes[..., :2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    true_x1y1 = true_xy - true_wh / 2\n",
    "    true_x2y2 = true_xy + true_wh / 2\n",
    "    pred_xy = pred_boxes[..., :2]\n",
    "    pred_wh = pred_boxes[..., 2:4]\n",
    "    pred_x1y1 = pred_xy - pred_wh / 2\n",
    "    pred_x2y2 = pred_xy + pred_wh / 2\n",
    "    intersect_x1 = tf.maximum(true_x1y1[..., 0], pred_x1y1[..., 0])\n",
    "    intersect_y1 = tf.maximum(true_x1y1[..., 1], pred_x1y1[..., 1])\n",
    "    intersect_x2 = tf.minimum(true_x2y2[..., 0], pred_x2y2[..., 0])\n",
    "    intersect_y2 = tf.minimum(true_x2y2[..., 1], pred_x2y2[..., 1])\n",
    "    intersect_area = tf.maximum(0.0, intersect_x2 - intersect_x1) * tf.maximum(0.0, intersect_y2 - intersect_y1)\n",
    "    true_area = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_area = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "    union_area = true_area + pred_area - intersect_area\n",
    "    iou = tf.math.divide_no_nan(intersect_area, union_area)\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOIoUMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='iou_metric', **kwargs):\n",
    "        super(YOLOIoUMetric, self).__init__(name=name, **kwargs)\n",
    "        self.total_iou = self.add_weight(name='total_iou', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        true_conf = y_true[..., 4]\n",
    "        pred_conf = y_pred[..., 4]\n",
    "        true_boxes = y_true[..., 0:4]\n",
    "        pred_boxes = y_pred[..., 0:4]\n",
    "        mask = tf.where(true_conf > 0)\n",
    "        true_boxes_masked = tf.gather_nd(true_boxes, mask)\n",
    "        pred_boxes_masked = tf.gather_nd(pred_boxes, mask)\n",
    "        ious = compute_iou_yolo(true_boxes_masked, pred_boxes_masked)\n",
    "        self.total_iou.assign_add(tf.reduce_sum(ious))\n",
    "        self.count.assign_add(tf.cast(tf.size(ious), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return tf.math.divide_no_nan(self.total_iou, self.count)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.total_iou.assign(0.0)\n",
    "        self.count.assign(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_loss(y_true, y_pred, num_classes=80):\n",
    "    true_box = y_true[..., :4]\n",
    "    true_conf = y_true[..., 4:5]\n",
    "    true_class = y_true[..., 5:]\n",
    "    pred_box = tf.sigmoid(y_pred[..., :4])\n",
    "    pred_conf = tf.sigmoid(y_pred[..., 4:5])\n",
    "    pred_class = tf.nn.softmax(y_pred[..., 5:])\n",
    "    iou = compute_iou_yolo(true_box, pred_box)\n",
    "    conf_loss = tf.keras.losses.binary_crossentropy(true_conf, pred_conf)\n",
    "    bbox_loss = tf.reduce_mean((true_box - pred_box) ** 2, axis=-1)\n",
    "    class_loss = tf.keras.losses.categorical_crossentropy(true_class, pred_class)\n",
    "    total_loss = bbox_loss + conf_loss + class_loss\n",
    "    return tf.reduce_mean(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=paths[\"Trained_model\"],\n",
    "    monitor='iou_metric',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficient_yolo_model(input_shape=(128, 128, 3), grid_size=8, num_classes=80)\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=yolo_loss,\n",
    "    metrics=[YOLOIoUMetric()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745253817.174081   84409 service.cc:146] XLA service 0x725fa00032b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745253817.174116   84409 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-04-21 22:13:37.346242: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-21 22:13:37.959971: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6/Unknown \u001b[1m15s\u001b[0m 25ms/step - iou_metric: 0.0000e+00 - loss: 12.6901"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745253827.385634   84409 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14575/Unknown \u001b[1m358s\u001b[0m 24ms/step - iou_metric: 0.0000e+00 - loss: 890931.0000"
     ]
    }
   ],
   "source": [
    "annotation_map = load_annotations(paths[\"Preprocessed_Train_json\"])\n",
    "train_dataset = build_tf_dataset(paths[\"Train_resized\"], annotation_map, batch_size=16)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
