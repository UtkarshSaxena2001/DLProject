{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 15:21:56.242965: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-21 15:21:56.254626: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-21 15:21:56.258031: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-21 15:21:56.267205: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json as js\n",
    "import tensorflow as tf\n",
    "from os import listdir as ld\n",
    "from os import path\n",
    "from keras.models import Model #type: ignore\n",
    "from keras import layers,models #type: ignore\n",
    "from tqdm import tqdm\n",
    "from keras.utils import to_categorical #type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config_CNN.json\",'r') as file:\n",
    "    paths = js.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Annotations: 100%|██████████| 40000/40000 [00:00<00:00, 473304.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Validation Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Annotations: 100%|██████████| 37000/37000 [00:00<00:00, 194841.92it/s]\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745229118.738089  649328 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745229118.789590  649328 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745229118.791629  649328 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745229118.798229  649328 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745229118.803462  649328 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745229118.807749  649328 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745229118.968150  649328 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745229118.972815  649328 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745229118.974942  649328 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-21 15:21:58.976758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3497 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_img_dir = paths['Train_resized']\n",
    "train_annotation = paths['Preprocessed_Train_json']\n",
    "val_img_dir = paths['Validation_resized']\n",
    "val_annotation = paths['Preprocessed_Validation_json']\n",
    "NUM_CLASSES = 80\n",
    "\n",
    "with open(train_annotation, 'r') as f:\n",
    "    train_annotations = js.load(f)\n",
    "\n",
    "with open(val_annotation, 'r') as f:\n",
    "    val_annotations = js.load(f)\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "print(\"Processing Training Data\")\n",
    "\n",
    "for info in tqdm(train_annotations, desc=\"Training Annotations\"):\n",
    "    bbox = info['bbox']\n",
    "    label = info['category_id']\n",
    "    image_path = path.join(train_img_dir, info[\"img_id\"])\n",
    "    train_data.append((image_path, bbox, label))\n",
    "\n",
    "print(\"Processing Validation Data\")\n",
    "\n",
    "for info in tqdm(val_annotations, desc=\"Validation Annotations\"):\n",
    "    bbox = info['bbox']\n",
    "    label = info['category_id']\n",
    "    image_path = path.join(val_img_dir, info[\"img_id\"])\n",
    "    val_data.append((image_path, bbox, label))\n",
    "\n",
    "def preprocess_example(image_path, bbox, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [128, 128])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    img_shape = tf.shape(image)\n",
    "    img_h = tf.cast(img_shape[0], tf.float32)\n",
    "    img_w = tf.cast(img_shape[1], tf.float32)\n",
    "    bbox = tf.convert_to_tensor(bbox, dtype=tf.float32)\n",
    "    x = bbox[0] / img_w\n",
    "    y = bbox[1] / img_h\n",
    "    w = bbox[2] / img_w\n",
    "    h = bbox[3] / img_h\n",
    "    bbox_tensor = tf.stack([x, y, w, h])\n",
    "    class_tensor = tf.one_hot(label, depth=NUM_CLASSES)\n",
    "\n",
    "    return image, {\n",
    "        \"class_output\": class_tensor,\n",
    "        \"bbox_output\": bbox_tensor\n",
    "    }\n",
    "\n",
    "\n",
    "def create_dataset(data, batch_size=32, shuffle=True, show_progress=False):\n",
    "    if show_progress:\n",
    "        print(\"Preprocessing dataset with progress bar...\")\n",
    "        processed = []\n",
    "        for item in tqdm(data, desc=\"Preprocessing Samples\"):\n",
    "            processed.append(preprocess_example(*item))\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(processed)\n",
    "    else:\n",
    "        paths, bboxes, labels = zip(*data)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((list(paths), list(bboxes), list(labels)))\n",
    "        dataset = dataset.map(lambda p, b, l: preprocess_example(p, b, l), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(data))\n",
    "\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = create_dataset(train_data, batch_size=32, show_progress=False)\n",
    "val_dataset = create_dataset(val_data, batch_size=32, shuffle=False, show_progress=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou_tf(box1, box2):\n",
    "    box1_x1 = box1[:, 0]\n",
    "    box1_y1 = box1[:, 1]\n",
    "    box1_x2 = box1[:, 0] + box1[:, 2]\n",
    "    box1_y2 = box1[:, 1] + box1[:, 3]\n",
    "    box2_x1 = box2[:, 0]\n",
    "    box2_y1 = box2[:, 1]\n",
    "    box2_x2 = box2[:, 0] + box2[:, 2]\n",
    "    box2_y2 = box2[:, 1] + box2[:, 3]\n",
    "    x1 = tf.maximum(box1_x1, box2_x1)\n",
    "    y1 = tf.maximum(box1_y1, box2_y1)\n",
    "    x2 = tf.minimum(box1_x2, box2_x2)\n",
    "    y2 = tf.minimum(box1_y2, box2_y2)\n",
    "    intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "    area1 = box1[:, 2] * box1[:, 3]\n",
    "    area2 = box2[:, 2] * box2[:, 3]\n",
    "    union = area1 + area2 - intersection\n",
    "    return tf.math.divide_no_nan(intersection, union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IoUMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='iou_metric', **kwargs):\n",
    "        super(IoUMetric, self).__init__(name=name, **kwargs)\n",
    "        self.total_iou = self.add_weight(name='total_iou', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.reshape(y_true, (-1, 4))\n",
    "        y_pred = tf.reshape(y_pred, (-1, 4))\n",
    "        ious = compute_iou_tf(y_true, y_pred)\n",
    "        self.total_iou.assign_add(tf.reduce_sum(ious))\n",
    "        self.count.assign_add(tf.cast(tf.size(ious), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return tf.math.divide_no_nan(self.total_iou, self.count)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.total_iou.assign(0.0)\n",
    "        self.count.assign(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbconv_block(x, filters, kernel_size=(3, 3), strides=(1, 1), expand_ratio=6):\n",
    "    input_tensor = x\n",
    "    in_channels = x.shape[-1]\n",
    "    x = layers.Conv2D(in_channels * expand_ratio, (1, 1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, (1, 1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if strides == (1, 1) and in_channels == filters:\n",
    "        x = layers.Add()([input_tensor, x])\n",
    "    return x\n",
    "\n",
    "def simple_efficient_model(input_shape=(128, 128, 3), num_classes=80):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = mbconv_block(x, 64, strides=(1, 1), expand_ratio=2)\n",
    "    x = mbconv_block(x, 64, strides=(2, 2), expand_ratio=2)\n",
    "    x = mbconv_block(x, 128, strides=(1, 1), expand_ratio=4)\n",
    "    x = mbconv_block(x, 128, strides=(2,2), expand_ratio=4)\n",
    "    x = mbconv_block(x, 512, strides=(1, 1), expand_ratio=4)\n",
    "    x = mbconv_block(x, 512, strides=(2,2), expand_ratio=4)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    cls = layers.Dense(512, activation='relu')(x)\n",
    "    cls = layers.Dropout(0.4)(cls)\n",
    "    class_output = layers.Dense(num_classes, activation='softmax', name=\"class_output\")(cls)\n",
    "    bbox = layers.Dense(64, activation='relu')(x)\n",
    "    bbox_output = layers.Dense(4, activation='sigmoid', name=\"bbox_output\")(bbox)\n",
    "    model = models.Model(inputs, {\"class_output\": class_output, \"bbox_output\": bbox_output})\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-2),\n",
    "        loss={\n",
    "            \"class_output\": \"categorical_crossentropy\",\n",
    "            \"bbox_output\": IoUMetric()\n",
    "        },\n",
    "        metrics={\n",
    "            \"class_output\": \"accuracy\",\n",
    "            \"bbox_output\": IoUMetric()\n",
    "        }\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = simple_efficient_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = paths[\"Trained_model\"],\n",
    "    monitor = 'bbox_output_iou_metric',\n",
    "    save_best_only = True,\n",
    "    save_weights_only = False,\n",
    "    mode = 'max',\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utkarsh/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:731: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n",
      "I0000 00:00:1745229127.816651  649422 service.cc:146] XLA service 0x76f91004d720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745229127.816679  649422 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-04-21 15:22:07.993623: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-21 15:22:08.669733: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n",
      "2025-04-21 15:22:10.864700: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5818', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-04-21 15:22:11.210524: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5818', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-04-21 15:22:11.360055: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5818', 36 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   3/1250\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 57ms/step - bbox_output_iou_metric: 0.1317 - bbox_output_loss: 0.1221 - class_output_accuracy: 0.0087 - class_output_loss: 4.4478 - loss: 4.5699    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745229145.349575  649422 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - bbox_output_iou_metric: 0.1078 - bbox_output_loss: 0.1267 - class_output_accuracy: 0.0153 - class_output_loss: 3090.0513 - loss: 3090.1782\n",
      "Epoch 1: bbox_output_iou_metric improved from -inf to 0.06109, saving model to /home/utkarsh/Desktop/Sem-2/Deep Learning/2024PGCSDS14_Utkarsh Saxena_DeepLearning/DLProject/best_model_bbox.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 70ms/step - bbox_output_iou_metric: 0.1078 - bbox_output_loss: 0.1267 - class_output_accuracy: 0.0153 - class_output_loss: 3102.7534 - loss: 3102.8806 - val_bbox_output_iou_metric: 4.4884e-08 - val_bbox_output_loss: 0.0432 - val_class_output_accuracy: 0.0135 - val_class_output_loss: 83806.0156 - val_loss: 83771.4688\n",
      "Epoch 2/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - bbox_output_iou_metric: 3.9585e-06 - bbox_output_loss: 0.0283 - class_output_accuracy: 0.0129 - class_output_loss: 196844.5625 - loss: 196844.5781\n",
      "Epoch 2: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 66ms/step - bbox_output_iou_metric: 3.9659e-06 - bbox_output_loss: 0.0283 - class_output_accuracy: 0.0129 - class_output_loss: 196933.0625 - loss: 196933.0781 - val_bbox_output_iou_metric: 0.0000e+00 - val_bbox_output_loss: 0.0181 - val_class_output_accuracy: 0.0000e+00 - val_class_output_loss: 535973.7500 - val_loss: 536031.9375\n",
      "Epoch 3/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - bbox_output_iou_metric: 2.2941e-04 - bbox_output_loss: 0.0150 - class_output_accuracy: 0.0126 - class_output_loss: 656034.5000 - loss: 656034.5000\n",
      "Epoch 3: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 66ms/step - bbox_output_iou_metric: 2.2959e-04 - bbox_output_loss: 0.0150 - class_output_accuracy: 0.0126 - class_output_loss: 656136.7500 - loss: 656136.7500 - val_bbox_output_iou_metric: 6.7375e-06 - val_bbox_output_loss: 0.0116 - val_class_output_accuracy: 0.0135 - val_class_output_loss: 1695435.1250 - val_loss: 1695667.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - bbox_output_iou_metric: 4.7527e-04 - bbox_output_loss: 0.0102 - class_output_accuracy: 0.0131 - class_output_loss: 1183581.6250 - loss: 1183581.6250\n",
      "Epoch 4: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 66ms/step - bbox_output_iou_metric: 4.7539e-04 - bbox_output_loss: 0.0102 - class_output_accuracy: 0.0131 - class_output_loss: 1183710.0000 - loss: 1183710.0000 - val_bbox_output_iou_metric: 4.1671e-04 - val_bbox_output_loss: 0.0086 - val_class_output_accuracy: 0.0139 - val_class_output_loss: 1378449.1250 - val_loss: 1377725.7500\n",
      "Epoch 5/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - bbox_output_iou_metric: 6.2060e-04 - bbox_output_loss: 0.0079 - class_output_accuracy: 0.0129 - class_output_loss: 1829845.7500 - loss: 1829845.7500\n",
      "Epoch 5: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 67ms/step - bbox_output_iou_metric: 6.2042e-04 - bbox_output_loss: 0.0079 - class_output_accuracy: 0.0129 - class_output_loss: 1829983.6250 - loss: 1829983.6250 - val_bbox_output_iou_metric: 0.0018 - val_bbox_output_loss: 0.0070 - val_class_output_accuracy: 0.0141 - val_class_output_loss: 1414270.7500 - val_loss: 1409328.0000\n",
      "Epoch 6/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - bbox_output_iou_metric: 2.5757e-04 - bbox_output_loss: 0.0066 - class_output_accuracy: 0.0142 - class_output_loss: 2528330.5000 - loss: 2528330.5000\n",
      "Epoch 6: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 66ms/step - bbox_output_iou_metric: 2.5759e-04 - bbox_output_loss: 0.0066 - class_output_accuracy: 0.0142 - class_output_loss: 2528474.2500 - loss: 2528474.2500 - val_bbox_output_iou_metric: 4.6300e-04 - val_bbox_output_loss: 0.0059 - val_class_output_accuracy: 0.0135 - val_class_output_loss: 1906397.0000 - val_loss: 1904593.0000\n",
      "Epoch 7/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - bbox_output_iou_metric: 1.9214e-04 - bbox_output_loss: 0.0055 - class_output_accuracy: 0.0150 - class_output_loss: 3346722.5000 - loss: 3346722.5000\n",
      "Epoch 7: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 66ms/step - bbox_output_iou_metric: 1.9220e-04 - bbox_output_loss: 0.0055 - class_output_accuracy: 0.0150 - class_output_loss: 3346891.7500 - loss: 3346891.7500 - val_bbox_output_iou_metric: 1.2054e-04 - val_bbox_output_loss: 0.0050 - val_class_output_accuracy: 0.0000e+00 - val_class_output_loss: 4049947.0000 - val_loss: 4042879.5000\n",
      "Epoch 8/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - bbox_output_iou_metric: 2.6586e-04 - bbox_output_loss: 0.0048 - class_output_accuracy: 0.0132 - class_output_loss: 4150244.0000 - loss: 4150244.0000\n",
      "Epoch 8: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 66ms/step - bbox_output_iou_metric: 2.6583e-04 - bbox_output_loss: 0.0048 - class_output_accuracy: 0.0132 - class_output_loss: 4150453.7500 - loss: 4150453.7500 - val_bbox_output_iou_metric: 7.2509e-06 - val_bbox_output_loss: 0.0044 - val_class_output_accuracy: 0.0000e+00 - val_class_output_loss: 4893060.0000 - val_loss: 4886460.5000\n",
      "Epoch 9/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - bbox_output_iou_metric: 1.8749e-04 - bbox_output_loss: 0.0042 - class_output_accuracy: 0.0122 - class_output_loss: 5049248.0000 - loss: 5049248.0000\n",
      "Epoch 9: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 66ms/step - bbox_output_iou_metric: 1.8748e-04 - bbox_output_loss: 0.0042 - class_output_accuracy: 0.0122 - class_output_loss: 5049498.5000 - loss: 5049498.5000 - val_bbox_output_iou_metric: 9.5303e-06 - val_bbox_output_loss: 0.0039 - val_class_output_accuracy: 0.0135 - val_class_output_loss: 10472544.0000 - val_loss: 10450186.0000\n",
      "Epoch 10/20\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - bbox_output_iou_metric: 2.0874e-04 - bbox_output_loss: 0.0038 - class_output_accuracy: 0.0124 - class_output_loss: 6373918.0000 - loss: 6373918.0000\n",
      "Epoch 10: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 59ms/step - bbox_output_iou_metric: 2.0871e-04 - bbox_output_loss: 0.0038 - class_output_accuracy: 0.0124 - class_output_loss: 6374091.0000 - loss: 6374091.0000 - val_bbox_output_iou_metric: 2.0078e-04 - val_bbox_output_loss: 0.0035 - val_class_output_accuracy: 0.0143 - val_class_output_loss: 7671272.5000 - val_loss: 7664138.5000\n",
      "Epoch 11/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - bbox_output_iou_metric: 1.9090e-04 - bbox_output_loss: 0.0034 - class_output_accuracy: 0.0133 - class_output_loss: 7036971.0000 - loss: 7036971.0000\n",
      "Epoch 11: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 66ms/step - bbox_output_iou_metric: 1.9089e-04 - bbox_output_loss: 0.0034 - class_output_accuracy: 0.0133 - class_output_loss: 7037301.5000 - loss: 7037301.5000 - val_bbox_output_iou_metric: 5.1458e-04 - val_bbox_output_loss: 0.0032 - val_class_output_accuracy: 0.0140 - val_class_output_loss: 5477096.0000 - val_loss: 5475155.5000\n",
      "Epoch 12/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - bbox_output_iou_metric: 1.0259e-04 - bbox_output_loss: 0.0031 - class_output_accuracy: 0.0120 - class_output_loss: 8401481.0000 - loss: 8401481.0000\n",
      "Epoch 12: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 66ms/step - bbox_output_iou_metric: 1.0260e-04 - bbox_output_loss: 0.0031 - class_output_accuracy: 0.0120 - class_output_loss: 8401743.0000 - loss: 8401743.0000 - val_bbox_output_iou_metric: 7.5406e-07 - val_bbox_output_loss: 0.0030 - val_class_output_accuracy: 0.0135 - val_class_output_loss: 10298557.0000 - val_loss: 10285204.0000\n",
      "Epoch 13/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - bbox_output_iou_metric: 9.1736e-05 - bbox_output_loss: 0.0029 - class_output_accuracy: 0.0135 - class_output_loss: 9628817.0000 - loss: 9628817.0000\n",
      "Epoch 13: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 66ms/step - bbox_output_iou_metric: 9.1729e-05 - bbox_output_loss: 0.0029 - class_output_accuracy: 0.0135 - class_output_loss: 9629110.0000 - loss: 9629110.0000 - val_bbox_output_iou_metric: 4.1143e-06 - val_bbox_output_loss: 0.0027 - val_class_output_accuracy: 0.0135 - val_class_output_loss: 11859079.0000 - val_loss: 11865868.0000\n",
      "Epoch 14/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - bbox_output_iou_metric: 4.0828e-05 - bbox_output_loss: 0.0027 - class_output_accuracy: 0.0132 - class_output_loss: 11047529.0000 - loss: 11047529.0000\n",
      "Epoch 14: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 64ms/step - bbox_output_iou_metric: 4.0851e-05 - bbox_output_loss: 0.0027 - class_output_accuracy: 0.0132 - class_output_loss: 11047757.0000 - loss: 11047757.0000 - val_bbox_output_iou_metric: 4.5098e-06 - val_bbox_output_loss: 0.0025 - val_class_output_accuracy: 0.0136 - val_class_output_loss: 11523661.0000 - val_loss: 11526089.0000\n",
      "Epoch 15/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - bbox_output_iou_metric: 6.7234e-05 - bbox_output_loss: 0.0025 - class_output_accuracy: 0.0120 - class_output_loss: 12603337.0000 - loss: 12603337.0000\n",
      "Epoch 15: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 64ms/step - bbox_output_iou_metric: 6.7230e-05 - bbox_output_loss: 0.0025 - class_output_accuracy: 0.0120 - class_output_loss: 12603552.0000 - loss: 12603552.0000 - val_bbox_output_iou_metric: 7.3726e-05 - val_bbox_output_loss: 0.0024 - val_class_output_accuracy: 0.0135 - val_class_output_loss: 16574515.0000 - val_loss: 16570331.0000\n",
      "Epoch 16/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - bbox_output_iou_metric: 4.4226e-05 - bbox_output_loss: 0.0023 - class_output_accuracy: 0.0124 - class_output_loss: 14118712.0000 - loss: 14118712.0000\n",
      "Epoch 16: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 65ms/step - bbox_output_iou_metric: 4.4231e-05 - bbox_output_loss: 0.0023 - class_output_accuracy: 0.0124 - class_output_loss: 14118940.0000 - loss: 14118940.0000 - val_bbox_output_iou_metric: 0.0000e+00 - val_bbox_output_loss: 0.0022 - val_class_output_accuracy: 0.0135 - val_class_output_loss: 9779643.0000 - val_loss: 9781250.0000\n",
      "Epoch 17/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - bbox_output_iou_metric: 2.5360e-05 - bbox_output_loss: 0.0022 - class_output_accuracy: 0.0122 - class_output_loss: 15665555.0000 - loss: 15665555.0000\n",
      "Epoch 17: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 65ms/step - bbox_output_iou_metric: 2.5371e-05 - bbox_output_loss: 0.0022 - class_output_accuracy: 0.0122 - class_output_loss: 15666021.0000 - loss: 15666021.0000 - val_bbox_output_iou_metric: 0.0000e+00 - val_bbox_output_loss: 0.0021 - val_class_output_accuracy: 0.0000e+00 - val_class_output_loss: 15774583.0000 - val_loss: 15778394.0000\n",
      "Epoch 18/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - bbox_output_iou_metric: 2.3944e-05 - bbox_output_loss: 0.0021 - class_output_accuracy: 0.0115 - class_output_loss: 16941330.0000 - loss: 16941330.0000\n",
      "Epoch 18: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 65ms/step - bbox_output_iou_metric: 2.3956e-05 - bbox_output_loss: 0.0021 - class_output_accuracy: 0.0115 - class_output_loss: 16941700.0000 - loss: 16941700.0000 - val_bbox_output_iou_metric: 1.9541e-05 - val_bbox_output_loss: 0.0020 - val_class_output_accuracy: 0.0136 - val_class_output_loss: 18575370.0000 - val_loss: 18569300.0000\n",
      "Epoch 19/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - bbox_output_iou_metric: 4.0556e-05 - bbox_output_loss: 0.0019 - class_output_accuracy: 0.0131 - class_output_loss: 18810608.0000 - loss: 18810608.0000\n",
      "Epoch 19: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 65ms/step - bbox_output_iou_metric: 4.0550e-05 - bbox_output_loss: 0.0019 - class_output_accuracy: 0.0131 - class_output_loss: 18811072.0000 - loss: 18811072.0000 - val_bbox_output_iou_metric: 0.0000e+00 - val_bbox_output_loss: 0.0019 - val_class_output_accuracy: 0.0000e+00 - val_class_output_loss: 19189030.0000 - val_loss: 19192230.0000\n",
      "Epoch 20/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - bbox_output_iou_metric: 8.3489e-06 - bbox_output_loss: 0.0018 - class_output_accuracy: 0.0121 - class_output_loss: 20110130.0000 - loss: 20110130.0000\n",
      "Epoch 20: bbox_output_iou_metric did not improve from 0.06109\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 65ms/step - bbox_output_iou_metric: 8.3539e-06 - bbox_output_loss: 0.0018 - class_output_accuracy: 0.0121 - class_output_loss: 20110800.0000 - loss: 20110800.0000 - val_bbox_output_iou_metric: 2.5034e-06 - val_bbox_output_loss: 0.0018 - val_class_output_accuracy: 0.0138 - val_class_output_loss: 19135716.0000 - val_loss: 19141086.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x76fa22aae810>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs = 20,\n",
    "    validation_data = val_dataset,\n",
    "    callbacks = [checkpoint]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
