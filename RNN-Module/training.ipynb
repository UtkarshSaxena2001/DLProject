{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a2776c",
   "metadata": {},
   "source": [
    "importing libraries"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "b75496f8",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 1,
   "id": "b75496f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 12:26:07.002989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-25 12:26:07.039212: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-25 12:26:07.048873: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-25 12:26:07.222586: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
>>>>>>> bb122e6 (sync)
   "source": [
    "import json as js\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from keras import layers, optimizers\n",
    "from keras.models import Model #type: ignore\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed, Embedding #type: ignore\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e55bc2",
   "metadata": {},
   "source": [
    "loading paths"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 2,
>>>>>>> bb122e6 (sync)
   "id": "2e612b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Config_RNN.json','r') as file:\n",
    "    paths = js.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578de471",
   "metadata": {},
   "source": [
    "loading padded captions"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 3,
>>>>>>> bb122e6 (sync)
   "id": "22dcb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths[\"Padded_preprocessed_data\"],'r') as f:\n",
    "    padded_captions = js.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde1be88",
   "metadata": {},
   "source": [
    "Build vocabulary and one hot encoding"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 4,
>>>>>>> bb122e6 (sync)
   "id": "1b9891f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "vocab = set(word for cap in padded_captions for word in cap)\n",
    "word2idx = {word: idx for idx, word in enumerate(sorted(vocab))}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "# One-hot encode all captions\n",
    "one_hot_captions = []\n",
    "for cap in padded_captions:\n",
    "    encoded = []\n",
    "    for word in cap:\n",
    "        one_hot = [0] * vocab_size\n",
    "        one_hot[word2idx[word]] = 1\n",
    "        encoded.append(one_hot) \n",
    "    one_hot_captions.append(encoded)\n",
    "\n",
    "# Convert to numpy array if needed\n",
    "one_hot_captions = np.array(one_hot_captions)"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 5,
   "id": "057d1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "embedding_index = {}\n",
    "\n",
    "with open(paths[\"glove_file\"], 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = vector\n",
    "\n",
    "# Convert each caption\n",
    "glove_captions = []\n",
    "for cap in padded_captions:\n",
    "    encoded = [embedding_index.get(word, np.zeros(100)) for word in cap]\n",
    "    glove_captions.append(encoded)"
   ]
  },
  {
>>>>>>> bb122e6 (sync)
   "cell_type": "markdown",
   "id": "628b16f2",
   "metadata": {},
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 6,
>>>>>>> bb122e6 (sync)
   "id": "0608f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=padded_captions, vector_size=100, window=5, min_count=1, workers=4)\n",
    "w2v_captions = []\n",
    "\n",
    "for cap in padded_captions:\n",
    "    encoded = [model.wv[word] for word in cap]\n",
    "    w2v_captions.append(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875de4f",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 7,
>>>>>>> bb122e6 (sync)
   "id": "56788c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745564180.274846    5601 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745564180.723488    5601 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745564180.728529    5601 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745564180.733176    5601 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745564180.735758    5601 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745564180.739466    5601 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745564180.939026    5601 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745564180.941252    5601 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1745564180.943250    5601 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-25 12:26:20.946943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3475 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "input_seq_len = 158\n",
    "output_seq_len = 30\n",
    "vector_dim = 158\n",
    "hidden_units = 256 \n",
    "encoder_inputs = Input(shape=(input_seq_len, vector_dim))\n",
    "encoder = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(output_seq_len)(state_h)\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True)\n",
    "decoder_outputs = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n",
    "decoder_dense = TimeDistributed(Dense(vector_dim))\n",
    "final_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model(inputs=encoder_inputs, outputs=final_outputs)\n",
    "model.compile(optimizer='adam', loss='mse') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da2938",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 8,
>>>>>>> bb122e6 (sync)
   "id": "c6d075be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor shape: (591753, 2, 100)\n",
      "target_tensor shape: (591753, 0, 100)\n"
     ]
    },
    {
<<<<<<< HEAD
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_tensor shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, target_tensor\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# should be (N, 30)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Input layer: sequence of 158 vectors of size 158\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m([\n\u001b[0;32m     43\u001b[0m     Embedding(input_dim\u001b[38;5;241m=\u001b[39mvocab_size, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m158\u001b[39m, input_length\u001b[38;5;241m=\u001b[39minput_seq_len),\n\u001b[0;32m     44\u001b[0m     LSTM(hidden_units, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     45\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRepeatVector(output_seq_len),\n\u001b[0;32m     46\u001b[0m     LSTM(hidden_units, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     47\u001b[0m     TimeDistributed(Dense(vector_dim))\n\u001b[0;32m     48\u001b[0m ])\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# encoder_inputs = Input(shape=(input_seq_len, vector_dim))\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# # Encoder LSTM\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Build model\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# model = Model(inputs=encoder_inputs, outputs=final_outputs)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# or 'categorical_crossentropy' if doing classification\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
=======
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">424,960</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ repeat_vector_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,606</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158\u001b[0m, \u001b[38;5;34m158\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158\u001b[0m,      │    \u001b[38;5;34m424,960\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m525,312\u001b[0m │ repeat_vector_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m158\u001b[0m)   │     \u001b[38;5;34m40,606\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">990,878</span> (3.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m990,878\u001b[0m (3.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">990,878</span> (3.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m990,878\u001b[0m (3.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
>>>>>>> bb122e6 (sync)
    }
   ],
   "source": [
    "# Parameters\n",
    "vocab_size = 10000\n",
    "seq_length = 30\n",
    "units = 512\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "input_seq_len = 158\n",
    "output_seq_len = 30\n",
    "vector_dim = 158\n",
    "hidden_units = 256  # You can change as per your model size\n",
    "\n",
    "# ========== TEXT VECTORIZATION ==========\n",
    "vectorizer = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    pad_to_max_tokens=True\n",
    ")\n",
    "all_captions = [\"<start> \" + \" \".join(cap) + \" <end>\" for cap in padded_captions]\n",
    "\n",
    "vectorizer.adapt(all_captions)\n",
    "# input_tensor = np.array([np.mean(cap, axis=0) for cap in w2v_captions])\n",
    "w2v_captions = np.array(w2v_captions)\n",
    "input_tensor = np.array(w2v_captions[:, :input_seq_len])  # shape: (N, 158, 158)\n",
    "target_tensor = np.array(w2v_captions[:, input_seq_len:input_seq_len + output_seq_len])  # shape: (N, 30, 158)\n",
    "\n",
    "# ========== DATA SPLIT ==========\n",
    "split_index = int(0.8 * len(input_tensor))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (input_tensor[:split_index], target_tensor[:split_index])\n",
    ").shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (input_tensor[split_index:], target_tensor[split_index:])\n",
    ").batch(BATCH_SIZE)\n",
    "\n",
    "print(\"input_tensor shape:\", input_tensor.shape)  # should be (N, 158, 158)\n",
    "print(\"target_tensor shape:\", target_tensor.shape)  # should be (N, 30)\n",
    "\n",
    "# Input layer: sequence of 158 vectors of size 158\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8de6dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 158, 158)          1580000   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 256)               424960    \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 30, 256)          0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 30, 256)           525312    \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 30, 158)          40606     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,570,878\n",
      "Trainable params: 2,570,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=158, input_length=input_seq_len),\n",
    "    LSTM(hidden_units, return_sequences=False),\n",
    "    layers.RepeatVector(output_seq_len),\n",
    "    LSTM(hidden_units, return_sequences=True),\n",
    "    TimeDistributed(Dense(vector_dim))\n",
    "])\n",
    "\n",
    "\n",
    "# encoder_inputs = Input(shape=(input_seq_len, vector_dim))\n",
    "\n",
    "# # Encoder LSTM\n",
    "# encoder = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# # We only need the final states to initialize the decoder\n",
    "# decoder_inputs = layers.RepeatVector(output_seq_len)(state_h)\n",
    "\n",
    "# # Decoder LSTM\n",
    "# decoder_lstm = LSTM(hidden_units, return_sequences=True)\n",
    "# decoder_outputs = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n",
    "\n",
    "# # Output projection: make sure each time step outputs a 158-dim vector\n",
    "# decoder_dense = TimeDistributed(Dense(vector_dim))\n",
    "# final_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Build model\n",
    "# model = Model(inputs=encoder_inputs, outputs=final_outputs)\n",
    "model.compile(optimizer='adam', loss='mse')  # or 'categorical_crossentropy' if doing classification\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "b0f8145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
=======
   "execution_count": 9,
>>>>>>> bb122e6 (sync)
   "id": "2ad854ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
<<<<<<< HEAD
     "evalue": "in user code:\n\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 158), found shape=(None, 2, 100)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\YADAV_~1\\AppData\\Local\\Temp\\__autograph_generated_fileyt958kxy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 158), found shape=(None, 2, 100)\n"
=======
     "evalue": "Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 158, 158), found shape=(None, 2, 158)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/keras/src/layers/input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 158, 158), found shape=(None, 2, 158)"
>>>>>>> bb122e6 (sync)
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=val_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f509ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from keras import layers\n",
    "# # ========== SETUP ==========\n",
    "# vocab_size = 10000\n",
    "# seq_length = 30\n",
    "# embedding_dim = 100\n",
    "# units = 512\n",
    "# BATCH_SIZE = 64\n",
    "# EPOCHS = 10\n",
    "# # Sample input: padded_captions = [{'output': 'a man riding a bike'}, ...]\n",
    "# # Sample input: w2v_captions = [np.array([...]), np.array([...]), ...]\n",
    "# # ========== TEXT VECTORIZATION ==========\n",
    "# vectorizer = layers.TextVectorization(\n",
    "#     max_tokens=vocab_size,\n",
    "#     output_mode='int',\n",
    "#     output_sequence_length=seq_length,\n",
    "#     standardize='lower_and_strip_punctuation',\n",
    "#     split='whitespace',\n",
    "#     pad_to_max_tokens=True\n",
    "# )\n",
    "# all_captions = [\"<start> \" + item['output'] + \" <end>\" for item in padded_captions]\n",
    "# vectorizer.adapt(all_captions)\n",
    "\n",
    "# input_tensor = np.array([np.mean(cap, axis=0) for cap in w2v_captions])\n",
    "# target_tensor = vectorizer(tf.constant(all_captions)).numpy()\n",
    "\n",
    "# # ========== DATA SPLIT ==========\n",
    "# split_index = int(0.8 * len(input_tensor))\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "#     (input_tensor[:split_index], target_tensor[:split_index])\n",
    "# ).shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "#     (input_tensor[split_index:], target_tensor[split_index:])\n",
    "# ).batch(BATCH_SIZE)\n",
    "\n",
    "# # ========== MODEL SETUP ==========\n",
    "# import tensorflow as tf\n",
    "# from keras import layers, optimizers\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# # Define the Decoder\n",
    "# class RNN_Decoder(tf.keras.Model):\n",
    "#     def __init__(self, embedding_dim, units, vocab_size):\n",
    "#         super(RNN_Decoder, self).__init__()\n",
    "#         self.units = units\n",
    "#         self.embedding = layers.Embedding(vocab_size, embedding_dim)\n",
    "#         self.gru = layers.GRU(self.units,\n",
    "#                               return_sequences=True,\n",
    "#                               return_state=True,\n",
    "#                               recurrent_initializer='glorot_uniform')\n",
    "#         self.fc1 = layers.Dense(self.units)\n",
    "#         self.fc2 = layers.Dense(vocab_size)\n",
    "\n",
    "#     def call(self, x, features, hidden):\n",
    "#         x = self.embedding(x)\n",
    "#         features = tf.expand_dims(features, 1)\n",
    "#         features = tf.tile(features, [1, tf.shape(x)[1], 1])  # Match sequence length\n",
    "#         x = tf.concat([features, x], axis=-1)\n",
    "#         output, state = self.gru(x, initial_state=hidden)\n",
    "#         x = self.fc1(output)\n",
    "#         x = self.fc2(x)\n",
    "#         return x, state, None\n",
    "\n",
    "#     def reset_state(self, batch_size):\n",
    "#         return tf.zeros((batch_size, self.units))\n",
    "\n",
    "# # Loss and optimizer\n",
    "# loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "# def loss_function(real, pred):\n",
    "#     mask = tf.math.not_equal(real, 0)\n",
    "#     loss_ = loss_object(real, pred)\n",
    "#     mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "#     loss_ *= mask\n",
    "#     return tf.reduce_mean(loss_)\n",
    "\n",
    "# @tf.function\n",
    "# def train_step(img_tensor, target, decoder, optimizer):\n",
    "#     loss = 0\n",
    "#     batch_size = tf.shape(img_tensor)[0]\n",
    "#     hidden = decoder.reset_state(batch_size)\n",
    "#     dec_input = target[:, :-1]\n",
    "#     real = target[:, 1:]\n",
    "\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         predictions, _, _ = decoder(dec_input, img_tensor, hidden)\n",
    "#         loss = loss_function(real, predictions)\n",
    "\n",
    "#     trainable_variables = decoder.trainable_variables\n",
    "#     gradients = tape.gradient(loss, trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "#     return loss\n",
    "\n",
    "# @tf.function\n",
    "# def validation_step(img_tensor, target, decoder):\n",
    "#     loss = 0\n",
    "#     batch_size = tf.shape(img_tensor)[0]\n",
    "#     hidden = decoder.reset_state(batch_size)\n",
    "#     dec_input = target[:, :-1]\n",
    "#     real = target[:, 1:]\n",
    "\n",
    "#     predictions, _, _ = decoder(dec_input, img_tensor, hidden)\n",
    "#     loss = loss_function(real, predictions)\n",
    "\n",
    "#     return loss\n",
    "\n",
    "# def train_model(train_dataset, val_dataset, decoder, optimizer, epochs, save_path):\n",
    "#     best_val_loss = float('inf')\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "#         total_loss = 0\n",
    "#         for img_tensor, target in tqdm(train_dataset, desc=\"Training\"):\n",
    "#             batch_loss = train_step(img_tensor, target, decoder, optimizer)\n",
    "#             total_loss += batch_loss\n",
    "\n",
    "#         print(f\"Training Loss: {total_loss/len(train_dataset):.4f}\")\n",
    "\n",
    "#         total_val_loss = 0\n",
    "#         for img_tensor, target in tqdm(val_dataset, desc=\"Validating\"):\n",
    "#             batch_val_loss = validation_step(img_tensor, target, decoder)\n",
    "#             total_val_loss += batch_val_loss\n",
    "\n",
    "#         val_loss = total_val_loss / len(val_dataset)\n",
    "#         print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "#         if val_loss < best_val_loss:\n",
    "#             print(\"Validation loss improved. Saving model.\")\n",
    "#             decoder.save_weights(save_path)\n",
    "#             best_val_loss = val_loss\n",
    "#         else:\n",
    "#             print(\"Validation loss did not improve.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01243f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn = RNN_Decoder(embedding_dim, units, vocab_size)\n",
    "# train_model(train_dataset, val_dataset, rnn, optimizers.Adam(), 10, paths[\"Trained_model_RNN\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
