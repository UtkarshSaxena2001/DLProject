{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a2776c",
   "metadata": {},
   "source": [
    "importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75496f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as js\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from keras import layers, optimizers\n",
    "from keras.models import Model #type: ignore\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed, Embedding #type: ignore\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e55bc2",
   "metadata": {},
   "source": [
    "loading paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e612b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Config_RNN.json','r') as file:\n",
    "    paths = js.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578de471",
   "metadata": {},
   "source": [
    "loading padded captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22dcb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths[\"Padded_preprocessed_data\"],'r') as f:\n",
    "    padded_captions = js.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde1be88",
   "metadata": {},
   "source": [
    "Build vocabulary and one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b9891f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "vocab = set(word for cap in padded_captions for word in cap)\n",
    "word2idx = {word: idx for idx, word in enumerate(sorted(vocab))}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "# One-hot encode all captions\n",
    "one_hot_captions = []\n",
    "for cap in padded_captions:\n",
    "    encoded = []\n",
    "    for word in cap:\n",
    "        one_hot = [0] * vocab_size\n",
    "        one_hot[word2idx[word]] = 1\n",
    "        encoded.append(one_hot) \n",
    "    one_hot_captions.append(encoded)\n",
    "\n",
    "# Convert to numpy array if needed\n",
    "one_hot_captions = np.array(one_hot_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b16f2",
   "metadata": {},
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0608f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=padded_captions, vector_size=100, window=5, min_count=1, workers=4)\n",
    "w2v_captions = []\n",
    "\n",
    "for cap in padded_captions:\n",
    "    encoded = [model.wv[word] for word in cap]\n",
    "    w2v_captions.append(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875de4f",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56788c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_len = 158\n",
    "output_seq_len = 30\n",
    "vector_dim = 158\n",
    "hidden_units = 256 \n",
    "encoder_inputs = Input(shape=(input_seq_len, vector_dim))\n",
    "encoder = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(output_seq_len)(state_h)\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True)\n",
    "decoder_outputs = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n",
    "decoder_dense = TimeDistributed(Dense(vector_dim))\n",
    "final_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model(inputs=encoder_inputs, outputs=final_outputs)\n",
    "model.compile(optimizer='adam', loss='mse') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da2938",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d075be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor shape: (591753, 2, 100)\n",
      "target_tensor shape: (591753, 0, 100)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_tensor shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, target_tensor\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# should be (N, 30)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Input layer: sequence of 158 vectors of size 158\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m([\n\u001b[0;32m     43\u001b[0m     Embedding(input_dim\u001b[38;5;241m=\u001b[39mvocab_size, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m158\u001b[39m, input_length\u001b[38;5;241m=\u001b[39minput_seq_len),\n\u001b[0;32m     44\u001b[0m     LSTM(hidden_units, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     45\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRepeatVector(output_seq_len),\n\u001b[0;32m     46\u001b[0m     LSTM(hidden_units, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     47\u001b[0m     TimeDistributed(Dense(vector_dim))\n\u001b[0;32m     48\u001b[0m ])\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# encoder_inputs = Input(shape=(input_seq_len, vector_dim))\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# # Encoder LSTM\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Build model\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# model = Model(inputs=encoder_inputs, outputs=final_outputs)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# or 'categorical_crossentropy' if doing classification\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "vocab_size = 10000\n",
    "seq_length = 30\n",
    "units = 512\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "input_seq_len = 158\n",
    "output_seq_len = 30\n",
    "vector_dim = 158\n",
    "hidden_units = 256  # You can change as per your model size\n",
    "\n",
    "# ========== TEXT VECTORIZATION ==========\n",
    "vectorizer = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    pad_to_max_tokens=True\n",
    ")\n",
    "all_captions = [\"<start> \" + \" \".join(cap) + \" <end>\" for cap in padded_captions]\n",
    "\n",
    "vectorizer.adapt(all_captions)\n",
    "# input_tensor = np.array([np.mean(cap, axis=0) for cap in w2v_captions])\n",
    "w2v_captions = np.array(w2v_captions)\n",
    "input_tensor = np.array(w2v_captions[:, :input_seq_len])  # shape: (N, 158, 158)\n",
    "target_tensor = np.array(w2v_captions[:, input_seq_len:input_seq_len + output_seq_len])  # shape: (N, 30, 158)\n",
    "\n",
    "# ========== DATA SPLIT ==========\n",
    "split_index = int(0.8 * len(input_tensor))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (input_tensor[:split_index], target_tensor[:split_index])\n",
    ").shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (input_tensor[split_index:], target_tensor[split_index:])\n",
    ").batch(BATCH_SIZE)\n",
    "\n",
    "print(\"input_tensor shape:\", input_tensor.shape)  # should be (N, 158, 158)\n",
    "print(\"target_tensor shape:\", target_tensor.shape)  # should be (N, 30)\n",
    "\n",
    "# Input layer: sequence of 158 vectors of size 158\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8de6dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 158, 158)          1580000   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 256)               424960    \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 30, 256)          0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 30, 256)           525312    \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 30, 158)          40606     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,570,878\n",
      "Trainable params: 2,570,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=158, input_length=input_seq_len),\n",
    "    LSTM(hidden_units, return_sequences=False),\n",
    "    layers.RepeatVector(output_seq_len),\n",
    "    LSTM(hidden_units, return_sequences=True),\n",
    "    TimeDistributed(Dense(vector_dim))\n",
    "])\n",
    "\n",
    "\n",
    "# encoder_inputs = Input(shape=(input_seq_len, vector_dim))\n",
    "\n",
    "# # Encoder LSTM\n",
    "# encoder = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# # We only need the final states to initialize the decoder\n",
    "# decoder_inputs = layers.RepeatVector(output_seq_len)(state_h)\n",
    "\n",
    "# # Decoder LSTM\n",
    "# decoder_lstm = LSTM(hidden_units, return_sequences=True)\n",
    "# decoder_outputs = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n",
    "\n",
    "# # Output projection: make sure each time step outputs a 158-dim vector\n",
    "# decoder_dense = TimeDistributed(Dense(vector_dim))\n",
    "# final_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Build model\n",
    "# model = Model(inputs=encoder_inputs, outputs=final_outputs)\n",
    "model.compile(optimizer='adam', loss='mse')  # or 'categorical_crossentropy' if doing classification\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f8145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ad854ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 158), found shape=(None, 2, 100)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\YADAV_~1\\AppData\\Local\\Temp\\__autograph_generated_fileyt958kxy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\YADAV_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 158), found shape=(None, 2, 100)\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=val_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f509ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from keras import layers\n",
    "# # ========== SETUP ==========\n",
    "# vocab_size = 10000\n",
    "# seq_length = 30\n",
    "# embedding_dim = 100\n",
    "# units = 512\n",
    "# BATCH_SIZE = 64\n",
    "# EPOCHS = 10\n",
    "# # Sample input: padded_captions = [{'output': 'a man riding a bike'}, ...]\n",
    "# # Sample input: w2v_captions = [np.array([...]), np.array([...]), ...]\n",
    "# # ========== TEXT VECTORIZATION ==========\n",
    "# vectorizer = layers.TextVectorization(\n",
    "#     max_tokens=vocab_size,\n",
    "#     output_mode='int',\n",
    "#     output_sequence_length=seq_length,\n",
    "#     standardize='lower_and_strip_punctuation',\n",
    "#     split='whitespace',\n",
    "#     pad_to_max_tokens=True\n",
    "# )\n",
    "# all_captions = [\"<start> \" + item['output'] + \" <end>\" for item in padded_captions]\n",
    "# vectorizer.adapt(all_captions)\n",
    "\n",
    "# input_tensor = np.array([np.mean(cap, axis=0) for cap in w2v_captions])\n",
    "# target_tensor = vectorizer(tf.constant(all_captions)).numpy()\n",
    "\n",
    "# # ========== DATA SPLIT ==========\n",
    "# split_index = int(0.8 * len(input_tensor))\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "#     (input_tensor[:split_index], target_tensor[:split_index])\n",
    "# ).shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "#     (input_tensor[split_index:], target_tensor[split_index:])\n",
    "# ).batch(BATCH_SIZE)\n",
    "\n",
    "# # ========== MODEL SETUP ==========\n",
    "# import tensorflow as tf\n",
    "# from keras import layers, optimizers\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# # Define the Decoder\n",
    "# class RNN_Decoder(tf.keras.Model):\n",
    "#     def __init__(self, embedding_dim, units, vocab_size):\n",
    "#         super(RNN_Decoder, self).__init__()\n",
    "#         self.units = units\n",
    "#         self.embedding = layers.Embedding(vocab_size, embedding_dim)\n",
    "#         self.gru = layers.GRU(self.units,\n",
    "#                               return_sequences=True,\n",
    "#                               return_state=True,\n",
    "#                               recurrent_initializer='glorot_uniform')\n",
    "#         self.fc1 = layers.Dense(self.units)\n",
    "#         self.fc2 = layers.Dense(vocab_size)\n",
    "\n",
    "#     def call(self, x, features, hidden):\n",
    "#         x = self.embedding(x)\n",
    "#         features = tf.expand_dims(features, 1)\n",
    "#         features = tf.tile(features, [1, tf.shape(x)[1], 1])  # Match sequence length\n",
    "#         x = tf.concat([features, x], axis=-1)\n",
    "#         output, state = self.gru(x, initial_state=hidden)\n",
    "#         x = self.fc1(output)\n",
    "#         x = self.fc2(x)\n",
    "#         return x, state, None\n",
    "\n",
    "#     def reset_state(self, batch_size):\n",
    "#         return tf.zeros((batch_size, self.units))\n",
    "\n",
    "# # Loss and optimizer\n",
    "# loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "# def loss_function(real, pred):\n",
    "#     mask = tf.math.not_equal(real, 0)\n",
    "#     loss_ = loss_object(real, pred)\n",
    "#     mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "#     loss_ *= mask\n",
    "#     return tf.reduce_mean(loss_)\n",
    "\n",
    "# @tf.function\n",
    "# def train_step(img_tensor, target, decoder, optimizer):\n",
    "#     loss = 0\n",
    "#     batch_size = tf.shape(img_tensor)[0]\n",
    "#     hidden = decoder.reset_state(batch_size)\n",
    "#     dec_input = target[:, :-1]\n",
    "#     real = target[:, 1:]\n",
    "\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         predictions, _, _ = decoder(dec_input, img_tensor, hidden)\n",
    "#         loss = loss_function(real, predictions)\n",
    "\n",
    "#     trainable_variables = decoder.trainable_variables\n",
    "#     gradients = tape.gradient(loss, trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "#     return loss\n",
    "\n",
    "# @tf.function\n",
    "# def validation_step(img_tensor, target, decoder):\n",
    "#     loss = 0\n",
    "#     batch_size = tf.shape(img_tensor)[0]\n",
    "#     hidden = decoder.reset_state(batch_size)\n",
    "#     dec_input = target[:, :-1]\n",
    "#     real = target[:, 1:]\n",
    "\n",
    "#     predictions, _, _ = decoder(dec_input, img_tensor, hidden)\n",
    "#     loss = loss_function(real, predictions)\n",
    "\n",
    "#     return loss\n",
    "\n",
    "# def train_model(train_dataset, val_dataset, decoder, optimizer, epochs, save_path):\n",
    "#     best_val_loss = float('inf')\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "#         total_loss = 0\n",
    "#         for img_tensor, target in tqdm(train_dataset, desc=\"Training\"):\n",
    "#             batch_loss = train_step(img_tensor, target, decoder, optimizer)\n",
    "#             total_loss += batch_loss\n",
    "\n",
    "#         print(f\"Training Loss: {total_loss/len(train_dataset):.4f}\")\n",
    "\n",
    "#         total_val_loss = 0\n",
    "#         for img_tensor, target in tqdm(val_dataset, desc=\"Validating\"):\n",
    "#             batch_val_loss = validation_step(img_tensor, target, decoder)\n",
    "#             total_val_loss += batch_val_loss\n",
    "\n",
    "#         val_loss = total_val_loss / len(val_dataset)\n",
    "#         print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "#         if val_loss < best_val_loss:\n",
    "#             print(\"Validation loss improved. Saving model.\")\n",
    "#             decoder.save_weights(save_path)\n",
    "#             best_val_loss = val_loss\n",
    "#         else:\n",
    "#             print(\"Validation loss did not improve.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01243f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn = RNN_Decoder(embedding_dim, units, vocab_size)\n",
    "# train_model(train_dataset, val_dataset, rnn, optimizers.Adam(), 10, paths[\"Trained_model_RNN\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
