{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a2776c",
   "metadata": {},
   "source": [
    "importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec888453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\yadav_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\yadav_hmzx8cu\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
      "Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/24.0 MB 2.8 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.6/24.0 MB 4.6 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.9/24.0 MB 5.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.9/24.0 MB 5.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.5/24.0 MB 5.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.1/24.0 MB 5.9 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 8.7/24.0 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.0/24.0 MB 6.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.1/24.0 MB 7.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.5/24.0 MB 7.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.8/24.0 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.4/24.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.7/24.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.0 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading scipy-1.13.1-cp310-cp310-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 2.1/46.2 MB 9.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 3.1/46.2 MB 9.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.8/46.2 MB 8.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.1/46.2 MB 9.5 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 11.0/46.2 MB 10.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 13.6/46.2 MB 10.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 16.3/46.2 MB 11.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 19.4/46.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.9/46.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.0/46.2 MB 10.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 24.6/46.2 MB 10.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 26.7/46.2 MB 10.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.3/46.2 MB 10.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 30.4/46.2 MB 10.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 32.5/46.2 MB 10.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 34.9/46.2 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 36.4/46.2 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.3/46.2 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 40.1/46.2 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 41.4/46.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.4/46.2 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, scipy, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.1\n",
      "    Uninstalling scipy-1.14.1:\n",
      "      Successfully uninstalled scipy-1.14.1\n",
      "Successfully installed gensim-4.3.3 scipy-1.13.1 smart-open-7.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75496f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as js\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from keras import layers, optimizers\n",
    "from keras.models import Model #type: ignore\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed, Embedding #type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e55bc2",
   "metadata": {},
   "source": [
    "loading paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e612b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Config_RNN.json','r') as file:\n",
    "    paths = js.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578de471",
   "metadata": {},
   "source": [
    "loading padded captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22dcb58b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Padded_preprocessed_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPadded_preprocessed_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     padded_captions \u001b[38;5;241m=\u001b[39m js\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Padded_preprocessed_data'"
     ]
    }
   ],
   "source": [
    "with open(paths[\"Padded_preprocessed_data\"],'r') as f:\n",
    "    padded_captions = js.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde1be88",
   "metadata": {},
   "source": [
    "Build vocabulary and one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9891f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'padded_captions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Build vocabulary\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(word \u001b[38;5;28;01mfor\u001b[39;00m cap \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpadded_captions\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m cap)\n\u001b[0;32m      3\u001b[0m word2idx \u001b[38;5;241m=\u001b[39m {word: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28msorted\u001b[39m(vocab))}\n\u001b[0;32m      4\u001b[0m idx2word \u001b[38;5;241m=\u001b[39m {idx: word \u001b[38;5;28;01mfor\u001b[39;00m word, idx \u001b[38;5;129;01min\u001b[39;00m word2idx\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'padded_captions' is not defined"
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "vocab = set(word for cap in padded_captions for word in cap)\n",
    "word2idx = {word: idx for idx, word in enumerate(sorted(vocab))}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "# One-hot encode all captions\n",
    "one_hot_captions = []\n",
    "for cap in padded_captions:\n",
    "    encoded = []\n",
    "    for word in cap:\n",
    "        one_hot = [0] * vocab_size\n",
    "        one_hot[word2idx[word]] = 1\n",
    "        encoded.append(one_hot) \n",
    "    one_hot_captions.append(encoded)\n",
    "\n",
    "# Convert to numpy array if needed\n",
    "one_hot_captions = np.array(one_hot_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "057d1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "embedding_index = {}\n",
    "\n",
    "with open(paths[\"glove_file\"], 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = vector\n",
    "\n",
    "# Convert each caption\n",
    "glove_captions = []\n",
    "for cap in padded_captions:\n",
    "    encoded = [embedding_index.get(word, np.zeros(100)) for word in cap]\n",
    "    glove_captions.append(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b16f2",
   "metadata": {},
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0608f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=padded_captions, vector_size=100, window=5, min_count=1, workers=4)\n",
    "w2v_captions = []\n",
    "\n",
    "for cap in padded_captions:\n",
    "    encoded = [model.wv[word] for word in cap]\n",
    "    w2v_captions.append(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875de4f",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56788c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_len = 158\n",
    "output_seq_len = 30\n",
    "vector_dim = 158\n",
    "hidden_units = 256 \n",
    "encoder_inputs = Input(shape=(input_seq_len, vector_dim))\n",
    "encoder = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(output_seq_len)(state_h)\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True)\n",
    "decoder_outputs = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n",
    "decoder_dense = TimeDistributed(Dense(vector_dim))\n",
    "final_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model(inputs=encoder_inputs, outputs=final_outputs)\n",
    "model.compile(optimizer='adam', loss='mse') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da2938",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d075be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor shape: (591753, 2, 100)\n",
      "target_tensor shape: (591753, 0, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">424,960</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ repeat_vector_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ lstm_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
       "│                     │                   │            │ lstm_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_6  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,606</span> │ lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158\u001b[0m, \u001b[38;5;34m158\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158\u001b[0m,      │    \u001b[38;5;34m424,960\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m525,312\u001b[0m │ repeat_vector_6[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ lstm_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
       "│                     │                   │            │ lstm_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_6  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m158\u001b[0m)   │     \u001b[38;5;34m40,606\u001b[0m │ lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">990,878</span> (3.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m990,878\u001b[0m (3.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">990,878</span> (3.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m990,878\u001b[0m (3.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed\n",
    "# Parameters\n",
    "vocab_size = 10000\n",
    "seq_length = 30\n",
    "units = 512\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "input_seq_len = 158\n",
    "output_seq_len = 30\n",
    "vector_dim = 158\n",
    "hidden_units = 256  # You can change as per your model size\n",
    "\n",
    "# ========== TEXT VECTORIZATION ==========\n",
    "vectorizer = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    pad_to_max_tokens=True\n",
    ")\n",
    "all_captions = [\"<start> \" + item['output'] + \" <end>\" for item in padded_captions]\n",
    "vectorizer.adapt(all_captions)\n",
    "# input_tensor = np.array([np.mean(cap, axis=0) for cap in w2v_captions])\n",
    "w2v_captions = np.array(w2v_captions)\n",
    "input_tensor = np.array(w2v_captions[:, :input_seq_len])  # shape: (N, 158, 158)\n",
    "target_tensor = np.array(w2v_captions[:, input_seq_len:input_seq_len + output_seq_len])  # shape: (N, 30, 158)\n",
    "\n",
    "# ========== DATA SPLIT ==========\n",
    "split_index = int(0.8 * len(input_tensor))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (input_tensor[:split_index], target_tensor[:split_index])\n",
    ").shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (input_tensor[split_index:], target_tensor[split_index:])\n",
    ").batch(BATCH_SIZE)\n",
    "\n",
    "print(\"input_tensor shape:\", input_tensor.shape)  # should be (N, 158, 158)\n",
    "print(\"target_tensor shape:\", target_tensor.shape)  # should be (N, 30)\n",
    "\n",
    "# Input layer: sequence of 158 vectors of size 158\n",
    "encoder_inputs = Input(shape=(input_seq_len, vector_dim))\n",
    "\n",
    "# Encoder LSTM\n",
    "encoder = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We only need the final states to initialize the decoder\n",
    "decoder_inputs = layers.RepeatVector(output_seq_len)(state_h)\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True)\n",
    "decoder_outputs = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n",
    "\n",
    "# Output projection: make sure each time step outputs a 158-dim vector\n",
    "decoder_dense = TimeDistributed(Dense(vector_dim))\n",
    "final_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=encoder_inputs, outputs=final_outputs)\n",
    "model.compile(optimizer='adam', loss='mse')  # or 'categorical_crossentropy' if doing classification\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad854ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_6\" is incompatible with the layer: expected shape=(None, 158, 158), found shape=(None, 2, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/keras/src/layers/input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional_6\" is incompatible with the layer: expected shape=(None, 158, 158), found shape=(None, 2, 100)"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=val_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f509ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from keras import layers\n",
    "# # ========== SETUP ==========\n",
    "# vocab_size = 10000\n",
    "# seq_length = 30\n",
    "# embedding_dim = 100\n",
    "# units = 512\n",
    "# BATCH_SIZE = 64\n",
    "# EPOCHS = 10\n",
    "# # Sample input: padded_captions = [{'output': 'a man riding a bike'}, ...]\n",
    "# # Sample input: w2v_captions = [np.array([...]), np.array([...]), ...]\n",
    "# # ========== TEXT VECTORIZATION ==========\n",
    "# vectorizer = layers.TextVectorization(\n",
    "#     max_tokens=vocab_size,\n",
    "#     output_mode='int',\n",
    "#     output_sequence_length=seq_length,\n",
    "#     standardize='lower_and_strip_punctuation',\n",
    "#     split='whitespace',\n",
    "#     pad_to_max_tokens=True\n",
    "# )\n",
    "# all_captions = [\"<start> \" + item['output'] + \" <end>\" for item in padded_captions]\n",
    "# vectorizer.adapt(all_captions)\n",
    "\n",
    "# input_tensor = np.array([np.mean(cap, axis=0) for cap in w2v_captions])\n",
    "# target_tensor = vectorizer(tf.constant(all_captions)).numpy()\n",
    "\n",
    "# # ========== DATA SPLIT ==========\n",
    "# split_index = int(0.8 * len(input_tensor))\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "#     (input_tensor[:split_index], target_tensor[:split_index])\n",
    "# ).shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "#     (input_tensor[split_index:], target_tensor[split_index:])\n",
    "# ).batch(BATCH_SIZE)\n",
    "\n",
    "# # ========== MODEL SETUP ==========\n",
    "# import tensorflow as tf\n",
    "# from keras import layers, optimizers\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# # Define the Decoder\n",
    "# class RNN_Decoder(tf.keras.Model):\n",
    "#     def __init__(self, embedding_dim, units, vocab_size):\n",
    "#         super(RNN_Decoder, self).__init__()\n",
    "#         self.units = units\n",
    "#         self.embedding = layers.Embedding(vocab_size, embedding_dim)\n",
    "#         self.gru = layers.GRU(self.units,\n",
    "#                               return_sequences=True,\n",
    "#                               return_state=True,\n",
    "#                               recurrent_initializer='glorot_uniform')\n",
    "#         self.fc1 = layers.Dense(self.units)\n",
    "#         self.fc2 = layers.Dense(vocab_size)\n",
    "\n",
    "#     def call(self, x, features, hidden):\n",
    "#         x = self.embedding(x)\n",
    "#         features = tf.expand_dims(features, 1)\n",
    "#         features = tf.tile(features, [1, tf.shape(x)[1], 1])  # Match sequence length\n",
    "#         x = tf.concat([features, x], axis=-1)\n",
    "#         output, state = self.gru(x, initial_state=hidden)\n",
    "#         x = self.fc1(output)\n",
    "#         x = self.fc2(x)\n",
    "#         return x, state, None\n",
    "\n",
    "#     def reset_state(self, batch_size):\n",
    "#         return tf.zeros((batch_size, self.units))\n",
    "\n",
    "# # Loss and optimizer\n",
    "# loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "# def loss_function(real, pred):\n",
    "#     mask = tf.math.not_equal(real, 0)\n",
    "#     loss_ = loss_object(real, pred)\n",
    "#     mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "#     loss_ *= mask\n",
    "#     return tf.reduce_mean(loss_)\n",
    "\n",
    "# @tf.function\n",
    "# def train_step(img_tensor, target, decoder, optimizer):\n",
    "#     loss = 0\n",
    "#     batch_size = tf.shape(img_tensor)[0]\n",
    "#     hidden = decoder.reset_state(batch_size)\n",
    "#     dec_input = target[:, :-1]\n",
    "#     real = target[:, 1:]\n",
    "\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         predictions, _, _ = decoder(dec_input, img_tensor, hidden)\n",
    "#         loss = loss_function(real, predictions)\n",
    "\n",
    "#     trainable_variables = decoder.trainable_variables\n",
    "#     gradients = tape.gradient(loss, trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "#     return loss\n",
    "\n",
    "# @tf.function\n",
    "# def validation_step(img_tensor, target, decoder):\n",
    "#     loss = 0\n",
    "#     batch_size = tf.shape(img_tensor)[0]\n",
    "#     hidden = decoder.reset_state(batch_size)\n",
    "#     dec_input = target[:, :-1]\n",
    "#     real = target[:, 1:]\n",
    "\n",
    "#     predictions, _, _ = decoder(dec_input, img_tensor, hidden)\n",
    "#     loss = loss_function(real, predictions)\n",
    "\n",
    "#     return loss\n",
    "\n",
    "# def train_model(train_dataset, val_dataset, decoder, optimizer, epochs, save_path):\n",
    "#     best_val_loss = float('inf')\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "#         total_loss = 0\n",
    "#         for img_tensor, target in tqdm(train_dataset, desc=\"Training\"):\n",
    "#             batch_loss = train_step(img_tensor, target, decoder, optimizer)\n",
    "#             total_loss += batch_loss\n",
    "\n",
    "#         print(f\"Training Loss: {total_loss/len(train_dataset):.4f}\")\n",
    "\n",
    "#         total_val_loss = 0\n",
    "#         for img_tensor, target in tqdm(val_dataset, desc=\"Validating\"):\n",
    "#             batch_val_loss = validation_step(img_tensor, target, decoder)\n",
    "#             total_val_loss += batch_val_loss\n",
    "\n",
    "#         val_loss = total_val_loss / len(val_dataset)\n",
    "#         print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "#         if val_loss < best_val_loss:\n",
    "#             print(\"Validation loss improved. Saving model.\")\n",
    "#             decoder.save_weights(save_path)\n",
    "#             best_val_loss = val_loss\n",
    "#         else:\n",
    "#             print(\"Validation loss did not improve.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01243f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn = RNN_Decoder(embedding_dim, units, vocab_size)\n",
    "# train_model(train_dataset, val_dataset, rnn, optimizers.Adam(), 10, paths[\"Trained_model_RNN\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
