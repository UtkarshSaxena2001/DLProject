{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e77e4f9",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d77c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as js\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from keras import layers, optimizers\n",
    "from keras.models import Model #type: ignore\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed, Embedding #type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321a601",
   "metadata": {},
   "source": [
    "loading paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63654dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Config_RNN.json','r') as file:\n",
    "    paths = js.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f095c",
   "metadata": {},
   "source": [
    "Loading initial train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6654e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths[\"Caption_Train\"],'r') as file:\n",
    "    train_data = js.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bfb3f6",
   "metadata": {},
   "source": [
    "Extracting imp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca0430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdict = {}\n",
    "newdict[\"img_data\"] = train_data[\"images\"]\n",
    "newdict[\"annotations_data\"] = train_data[\"annotations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057887c",
   "metadata": {},
   "source": [
    "Creating Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c8135aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = newdict[\"img_data\"]\n",
    "annotations_data = newdict[\"annotations_data\"]\n",
    "captions_dict = defaultdict(list)\n",
    "\n",
    "for ann in annotations_data:\n",
    "    captions_dict[ann[\"image_id\"]].append(ann[\"caption\"])\n",
    "\n",
    "image_caption_data = {}\n",
    "for img in img_data:\n",
    "    file_id = img[\"file_name\"]\n",
    "    img_id = img[\"id\"]\n",
    "    image_caption_data[file_id] = captions_dict[img_id]\n",
    "\n",
    "with open(paths[\"Corpus\"], \"w\") as f:\n",
    "    js.dump(image_caption_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbb6ea",
   "metadata": {},
   "source": [
    "loading corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1778a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths[\"Corpus\"], \"r\") as f:\n",
    "    Corpus_data = js.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78443197",
   "metadata": {},
   "source": [
    "Loading nltk dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1d98bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/rakshit2001/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/rakshit2001/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21ec34",
   "metadata": {},
   "source": [
    "Text Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "087c2368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118287/118287 [04:30<00:00, 437.29it/s]\n",
      "100%|██████████| 118287/118287 [00:02<00:00, 54733.55it/s]\n"
     ]
    }
   ],
   "source": [
    "pos_tagged_captions = {}\n",
    "noun_captions = {}\n",
    "\n",
    "for item in tqdm(Corpus_data):\n",
    "    tagged = []\n",
    "    for caption in Corpus_data[item]:\n",
    "        tokens = nltk.word_tokenize(caption)\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        tagged.append(pos_tags)\n",
    "    pos_tagged_captions[item] = tagged\n",
    "\n",
    "for image_id, tagged_captions in tqdm(pos_tagged_captions.items()):\n",
    "    noun_lists = []\n",
    "    for tagged in tagged_captions:\n",
    "        nouns = [word for word, tag in tagged if tag in ('NN', 'NNS', 'NNP', 'NNPS')]\n",
    "        noun_lists.append(nouns)\n",
    "    noun_captions[image_id] = noun_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efc476",
   "metadata": {},
   "source": [
    "storing noune tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551befd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths['Nouned_Corpus'],'w') as f:\n",
    "    js.dump(noun_captions,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdcf798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118287/118287 [00:01<00:00, 89170.10it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(paths[\"Corpus\"], 'r') as f1:\n",
    "    captions_data = js.load(f1)\n",
    "\n",
    "with open(paths['Nouned_Corpus'], 'r') as f2:\n",
    "    features_data = js.load(f2)\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for image_id,nouns in tqdm(features_data.items()): \n",
    "    noun_caption = zip(nouns, captions_data[image_id])\n",
    "    for noun, caption in noun_caption:\n",
    "        dataset.append({\n",
    "            \"input\": \" \".join(noun),\n",
    "            \"output\": caption\n",
    "        })\n",
    "\n",
    "with open(paths[\"Preprocessed_data\"], \"w\") as out_file:\n",
    "    js.dump(dataset, out_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c77a5",
   "metadata": {},
   "source": [
    "Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01fb441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All captions padded to length: 158\n"
     ]
    }
   ],
   "source": [
    "with open(paths[\"Preprocessed_data\"], 'r') as f:\n",
    "    data = js.load(f)\n",
    "\n",
    "max_length = max(len(item['input']) for item in data)\n",
    "\n",
    "for item in data:\n",
    "    item['input'] = item['input'].ljust(max_length)\n",
    "\n",
    "with open(paths[\"Padded_preprocessed_data\"], 'w') as f:\n",
    "    js.dump(data, f, indent=4)\n",
    "\n",
    "print(\"All captions padded to length:\", max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab99094e",
   "metadata": {},
   "source": [
    "Loading padded captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e10820",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths[\"Padded_preprocessed_data\"],'r') as f:\n",
    "    padded_captions = js.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b0446",
   "metadata": {},
   "source": [
    "Build vocabulary and one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b9106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(word for cap in padded_captions for word in cap)\n",
    "word2idx = {word: idx for idx, word in enumerate(sorted(vocab))}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "vocab_size = len(word2idx)\n",
    "one_hot_captions = []\n",
    "\n",
    "for cap in padded_captions:\n",
    "    encoded = []\n",
    "\n",
    "    for word in cap:\n",
    "        one_hot = [0] * vocab_size\n",
    "        one_hot[word2idx[word]] = 1\n",
    "        encoded.append(one_hot)\n",
    "\n",
    "    one_hot_captions.append(encoded)\n",
    "    \n",
    "one_hot_captions = np.array(one_hot_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b73122",
   "metadata": {},
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da993253",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=padded_captions, vector_size=100, window=5, min_count=1, workers=4)\n",
    "w2v_captions = []\n",
    "\n",
    "for cap in padded_captions:\n",
    "    encoded = [model.wv[word] for word in cap]\n",
    "    w2v_captions.append(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88babe6d",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea86e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_len = 158\n",
    "output_seq_len = 30\n",
    "vector_dim = 158\n",
    "hidden_units = 256 \n",
    "encoder_inputs = Input(shape=(input_seq_len, vector_dim))\n",
    "encoder = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(output_seq_len)(state_h)\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True)\n",
    "decoder_outputs = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n",
    "decoder_dense = TimeDistributed(Dense(vector_dim))\n",
    "final_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model(inputs=encoder_inputs, outputs=final_outputs)\n",
    "model.compile(optimizer='adam', loss='mse') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de8b81d",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "317c3f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units, vocab_size):\n",
    "        super(RNN_Decoder, self).__init__()\n",
    "        self.units = units\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = LSTM(self.units,\n",
    "                                return_sequences=True,\n",
    "                                return_state=True,\n",
    "                                recurrent_initializer='glorot_uniform')\n",
    "        self.fc = Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, features, hidden):\n",
    "        x = self.embedding(x)  \n",
    "        features = tf.expand_dims(features, 1)  \n",
    "        features = tf.tile(features, [1, tf.shape(x)[1], 1])  \n",
    "        x = tf.concat([features, x], axis=-1) \n",
    "        output, state_h, state_c = self.lstm(x, initial_state=hidden)\n",
    "        x = self.fc(output)\n",
    "        return x, state_h, state_c\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        return [tf.zeros((batch_size, self.units)), tf.zeros((batch_size, self.units))]\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "checkpoint_path = paths[\"Trained_model_RNN\"]\n",
    "\n",
    "def train_model(dataset, decoder, optimizer, epochs=10):\n",
    "    best_loss = float('inf')\n",
    "    loss_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        loss_metric.reset_state()\n",
    "\n",
    "        for step, (img_tensor, target) in enumerate(dataset):\n",
    "            batch_loss = train_step(img_tensor, target, decoder, optimizer)\n",
    "            loss_metric.update_state(batch_loss)\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(f\"Step {step}/{len(dataset)} - loss: {batch_loss:.4f}\")\n",
    "\n",
    "        epoch_loss = loss_metric.result().numpy()\n",
    "        print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            decoder.save_weights(checkpoint_path)\n",
    "            print(f\"Best model saved with loss: {best_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6063a4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9247 [00:00<?, ?it/s]2025-04-23 16:55:37.483498: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n",
      "100%|█████████▉| 9245/9247 [05:21<00:00, 28.90it/s]2025-04-23 17:00:58.087644: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "100%|██████████| 9247/9247 [05:21<00:00, 28.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9245/9247 [05:21<00:00, 28.89it/s]2025-04-23 17:06:19.523000: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "100%|██████████| 9247/9247 [05:21<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.1203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9247/9247 [05:21<00:00, 28.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.0724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9247/9247 [05:21<00:00, 28.69it/s]2025-04-23 17:17:02.892447: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "100%|██████████| 9247/9247 [05:21<00:00, 28.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.0441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9247/9247 [05:20<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 7743/9247 [04:28<00:52, 28.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 57\u001b[0m\n\u001b[1;32m     52\u001b[0m             total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(batch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 51\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(dataset, decoder, optimizer, epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, (img_tensor, target)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(dataset)):\n\u001b[0;32m---> 51\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(batch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_testing/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "seq_length = 30\n",
    "\n",
    "vectorizer = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    pad_to_max_tokens=True\n",
    ")\n",
    "\n",
    "all_captions = [\"<start> \" + item['output'] + \" <end>\" for item in padded_captions]\n",
    "vectorizer.adapt(all_captions)\n",
    "input_tensor = np.array([np.mean(cap, axis=0) for cap in w2v_captions])\n",
    "target_tensor = vectorizer(tf.constant(all_captions)).numpy()\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor, target_tensor))\n",
    "train_dataset = train_dataset.shuffle(1000).batch(BATCH_SIZE)\n",
    "embedding_dim = 100\n",
    "units = 512\n",
    "vocab_size = vectorizer.vocabulary_size()\n",
    "decoder = RNN_Decoder(embedding_dim, units, vocab_size)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "start_token = vectorizer('<start>').numpy()[0]\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.math.not_equal(real, 0)\n",
    "    mask = tf.cast(mask, loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(img_tensor, target, decoder, optimizer):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        dec_input = target[:, :-1]   \n",
    "        real_output = target[:, 1:]  \n",
    "        predictions, _, _ = decoder(dec_input, img_tensor, decoder.reset_state(tf.shape(img_tensor)[0]))\n",
    "        loss = loss_function(real_output, predictions)\n",
    "    gradients = tape.gradient(loss, decoder.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, decoder.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def train_model(dataset, decoder, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for (batch, (img_tensor, target)) in enumerate(tqdm(dataset)):\n",
    "            batch_loss = train_step(img_tensor, target, decoder, optimizer)\n",
    "            total_loss += batch_loss\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / (batch + 1):.4f}')\n",
    "\n",
    "\n",
    "train_model(train_dataset, decoder, optimizer, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
