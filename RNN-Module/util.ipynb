{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e77e4f9",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d77c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 21:36:25.260342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-23 21:36:25.272049: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-23 21:36:25.275511: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-23 21:36:25.284276: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json as js\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from keras import layers, optimizers\n",
    "from keras.models import Model #type: ignore\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed, Embedding #type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321a601",
   "metadata": {},
   "source": [
    "loading paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63654dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Config_RNN.json','r') as file:\n",
    "    paths = js.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f095c",
   "metadata": {},
   "source": [
    "Loading initial train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6654e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths[\"Caption_Train\"],'r') as file:\n",
    "    train_data = js.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bfb3f6",
   "metadata": {},
   "source": [
    "Extracting imp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca0430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdict = {}\n",
    "newdict[\"img_data\"] = train_data[\"images\"]\n",
    "newdict[\"annotations_data\"] = train_data[\"annotations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057887c",
   "metadata": {},
   "source": [
    "Creating Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c8135aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = newdict[\"img_data\"]\n",
    "annotations_data = newdict[\"annotations_data\"]\n",
    "captions_dict = defaultdict(list)\n",
    "\n",
    "for ann in annotations_data:\n",
    "    captions_dict[ann[\"image_id\"]].append(ann[\"caption\"])\n",
    "\n",
    "image_caption_data = {}\n",
    "for img in img_data:\n",
    "    file_id = img[\"file_name\"]\n",
    "    img_id = img[\"id\"]\n",
    "    image_caption_data[file_id] = captions_dict[img_id]\n",
    "\n",
    "with open(paths[\"Corpus\"], \"w\") as f:\n",
    "    js.dump(image_caption_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbb6ea",
   "metadata": {},
   "source": [
    "loading corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1778a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths[\"Corpus\"], \"r\") as f:\n",
    "    Corpus_data = js.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78443197",
   "metadata": {},
   "source": [
    "Loading nltk dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1d98bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/utkarsh/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/utkarsh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21ec34",
   "metadata": {},
   "source": [
    "Text Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "087c2368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118287/118287 [02:27<00:00, 800.80it/s]\n",
      "100%|██████████| 118287/118287 [00:03<00:00, 34755.79it/s]\n"
     ]
    }
   ],
   "source": [
    "pos_tagged_captions = {}\n",
    "noun_captions = {}\n",
    "\n",
    "for item in tqdm(Corpus_data):\n",
    "    tagged = []\n",
    "    for caption in Corpus_data[item]:\n",
    "        tokens = nltk.word_tokenize(caption)\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        tagged.append(pos_tags)\n",
    "    pos_tagged_captions[item] = tagged\n",
    "\n",
    "for image_id, tagged_captions in tqdm(pos_tagged_captions.items()):\n",
    "    noun_lists = []\n",
    "    for tagged in tagged_captions:\n",
    "        nouns = [word for word, tag in tagged if tag in ('NN', 'NNS', 'NNP', 'NNPS')]\n",
    "        noun_lists.append(nouns)\n",
    "    noun_captions[image_id] = noun_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efc476",
   "metadata": {},
   "source": [
    "storing noune tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551befd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths['Nouned_Corpus'],'w') as f:\n",
    "    js.dump(noun_captions,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdcf798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118287/118287 [00:00<00:00, 280761.48it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(paths[\"Corpus\"], 'r') as f1:\n",
    "    captions_data = js.load(f1)\n",
    "\n",
    "with open(paths['Nouned_Corpus'], 'r') as f2:\n",
    "    features_data = js.load(f2)\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for image_id,nouns in tqdm(features_data.items()): \n",
    "    noun_caption = zip(nouns, captions_data[image_id])\n",
    "    for noun, caption in noun_caption:\n",
    "        dataset.append({\n",
    "            \"input\": \" \".join(noun),\n",
    "            \"output\": caption\n",
    "        })\n",
    "\n",
    "with open(paths[\"Preprocessed_data\"], \"w\") as out_file:\n",
    "    js.dump(dataset, out_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c77a5",
   "metadata": {},
   "source": [
    "Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01fb441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All captions padded to length: 158\n"
     ]
    }
   ],
   "source": [
    "with open(paths[\"Preprocessed_data\"], 'r') as f:\n",
    "    data = js.load(f)\n",
    "\n",
    "max_length = max(len(item['input']) for item in data)\n",
    "\n",
    "for item in data:\n",
    "    item['input'] = item['input'].ljust(max_length)\n",
    "\n",
    "with open(paths[\"Padded_preprocessed_data\"], 'w') as f:\n",
    "    js.dump(data, f, indent=4)\n",
    "\n",
    "print(\"All captions padded to length:\", max_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
